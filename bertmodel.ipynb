{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel,BertConfig\n",
    "bert_config = BertConfig.from_pretrained(\n",
    "        './pretrained_bert', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/classifier/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at ./pretrained_bert were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: This is an example sentence.\n",
      "Word embeddings shape: torch.Size([1, 128, 768])\n",
      "First word embedding: tensor([-6.9157e-01,  6.4621e-01,  3.8267e-01, -1.3345e-01,  3.6252e-01,\n",
      "        -1.5946e+00,  3.5152e-01, -3.0817e-01, -4.8093e-01,  9.2755e-01,\n",
      "         4.5621e-01,  2.2870e-01,  1.1444e+00, -8.3591e-01,  1.1546e+00,\n",
      "        -4.0854e-01,  5.4363e-01, -1.2029e-01, -8.8330e-01, -1.0515e+00,\n",
      "         6.4792e-01,  2.2311e-01, -7.1067e-01, -3.1360e-01, -9.6933e-02,\n",
      "        -6.0401e-01, -1.5695e-01, -2.8907e-01,  3.6698e-02,  1.0562e+00,\n",
      "         4.8086e-01, -6.1158e-01, -9.8572e-01,  6.5449e-01,  2.2811e-01,\n",
      "        -6.0318e-01,  1.0654e+00,  1.1491e+00,  2.8085e-01, -8.4224e-01,\n",
      "         1.3277e-02,  1.3628e+00, -1.1223e-01,  8.4845e-01,  3.2972e-02,\n",
      "         3.9194e-01, -2.4491e-02,  2.0995e-01, -1.2136e+00, -2.6938e-01,\n",
      "         5.9671e-01,  7.1074e+00,  9.6101e-01,  1.3651e+00,  2.3200e-02,\n",
      "         4.2649e-02,  9.0205e-01, -1.4751e-01, -4.3311e-01, -1.6228e+00,\n",
      "        -5.8898e-01, -9.8898e-01,  8.4083e-01,  3.0131e-01, -1.7174e-03,\n",
      "        -1.1153e+00,  2.5523e-01, -8.5558e-02, -7.7181e-01, -6.8390e-01,\n",
      "        -1.6517e-01,  1.8454e-01, -8.2211e-02,  6.0629e-01, -7.8953e-01,\n",
      "        -6.2653e-01, -6.3347e-01,  7.4199e-01, -5.4461e-01, -2.1183e-01,\n",
      "        -3.8580e-01,  5.4082e-01,  3.9599e-02, -3.4007e-01,  8.0913e-02,\n",
      "        -5.1579e-01,  4.3589e-02, -2.1844e+00,  7.1625e-01,  6.1796e-01,\n",
      "        -5.6258e-01, -5.3829e-01, -8.7294e-01,  4.4729e-01,  1.8710e-01,\n",
      "         2.6365e-01,  5.8338e-01, -3.7933e-01, -4.3408e-01, -4.3165e-01,\n",
      "         6.0273e-01,  1.2846e+00,  2.0361e-01, -8.9051e-02, -1.2398e+00,\n",
      "         1.4762e-01, -9.5312e-01, -1.1355e+00,  1.0774e+00, -1.4279e-01,\n",
      "        -4.7900e-01, -1.3744e-01, -2.8736e-01, -1.0173e-01, -3.5736e-01,\n",
      "        -3.9469e-01,  7.7913e-02, -1.6452e-01, -2.7322e+00, -4.7962e-01,\n",
      "         9.6229e-01, -4.4233e-01, -3.5741e-01, -5.7136e-01,  4.9316e-01,\n",
      "        -1.6408e-01,  6.0780e-01,  7.4844e-01,  5.8345e-01,  5.2474e-01,\n",
      "         3.4275e-02,  2.7205e-01, -1.5239e+00, -5.1844e-01,  2.0354e+00,\n",
      "        -7.1352e-02, -1.2339e-01, -1.7914e-02,  7.2940e-02, -1.2897e-01,\n",
      "        -1.9759e-01, -5.9937e-01,  5.2207e-01,  3.3803e-01,  6.8427e-01,\n",
      "         8.4274e-01, -2.7369e-01, -4.0756e-01,  1.2392e+00,  4.6176e-02,\n",
      "        -6.5829e-01,  2.7079e-01, -2.1586e-01,  4.3297e-02, -2.3941e-01,\n",
      "        -1.2279e+00,  2.7870e-01, -4.3124e-01, -8.0600e-01,  5.2579e-01,\n",
      "        -2.9132e-01,  5.3577e-01, -5.8745e-01, -1.2406e+00, -4.8631e-01,\n",
      "        -1.0363e-01,  4.2672e-01, -2.6973e-01, -2.9801e-01, -8.6114e-01,\n",
      "        -5.7666e-01,  6.9003e-02, -6.3569e-02,  1.7202e+00,  4.6509e-01,\n",
      "        -4.3256e-01, -2.6558e-02, -2.5149e-01, -1.1583e+00,  8.9069e-01,\n",
      "        -1.0242e+00, -6.0155e-01, -4.3771e-01,  2.3225e-01, -1.5756e+00,\n",
      "        -1.0323e+00, -5.9838e-01,  1.2518e+00,  2.1002e-01, -3.5778e-01,\n",
      "         6.5494e-01, -5.9588e-01, -2.1394e+00, -1.1562e+00,  5.5949e-01,\n",
      "         1.5235e+00, -1.1710e+00,  2.2408e-01, -7.9387e-01, -2.9034e-01,\n",
      "        -1.4599e-01, -4.2778e-01, -1.7867e-01,  3.1174e-01,  4.9797e-01,\n",
      "         3.8319e-01, -3.4936e-01,  1.0289e+00,  1.5047e+00, -5.2306e-01,\n",
      "        -9.6111e-01, -2.0193e-02, -1.2682e-01,  1.4711e-01, -6.1144e-01,\n",
      "         9.8865e-01, -8.2017e-02, -5.0653e-01,  7.9888e-01, -1.4255e+00,\n",
      "         4.7642e-01, -2.9944e-01,  5.4306e-01, -9.4628e-01, -7.2785e-01,\n",
      "         1.4664e-01, -8.8583e-02,  2.5693e-01, -1.5015e+00, -3.6650e-02,\n",
      "        -3.5948e-01,  3.7809e-01, -2.1642e-01,  1.3084e-02, -1.0969e-01,\n",
      "         4.6000e-01,  3.9936e-01,  8.0900e-01,  6.5946e-01,  1.3671e-01,\n",
      "         3.5303e-01,  4.9543e-01,  5.6546e-02, -1.6602e-01, -1.2845e-01,\n",
      "         7.8004e-01, -5.0211e-01,  9.6813e-01,  7.9301e-01,  7.9474e-01,\n",
      "         9.1877e-03,  4.4816e-01,  6.6735e-01, -7.7420e-01,  2.6857e-01,\n",
      "         5.5373e-01, -3.6247e-01, -2.9715e-01, -3.6447e-01, -2.7192e-01,\n",
      "         1.3937e-01, -1.7171e-01,  1.8603e-01,  6.7895e-01,  6.1864e-01,\n",
      "         6.1224e-01,  1.3174e+00, -7.1535e-01, -4.5074e-01, -1.0596e+00,\n",
      "        -1.2297e-01, -3.1172e-02,  9.3926e-02,  9.1367e-01, -9.3536e-01,\n",
      "        -9.8323e-01,  1.0405e-01,  7.4829e-02,  2.1354e+00, -1.9719e-01,\n",
      "         1.3956e-01,  3.1256e-01,  5.9113e-01,  5.6315e-01, -7.1408e-01,\n",
      "         7.7999e-01,  8.2142e-01,  6.6641e-01,  4.2731e-01, -1.1556e+00,\n",
      "        -4.0617e-01,  1.9062e-01,  1.1381e+00,  6.2857e-01,  1.0523e+00,\n",
      "        -8.6163e-01,  9.5658e-01,  1.1926e+00,  4.0939e-01,  1.6204e+00,\n",
      "         2.7392e-01, -2.7209e-02, -6.9080e-01,  7.4159e-01,  3.0375e-01,\n",
      "         3.7111e-01,  9.9746e-02,  6.3480e-01, -6.9170e-01, -2.4462e-01,\n",
      "        -4.7877e-01, -4.1911e-01,  6.6917e-01,  4.3780e-01, -1.6281e-01,\n",
      "         1.6745e-01,  3.5901e-01, -1.5206e+00, -5.7473e-01,  2.3141e-01,\n",
      "         2.1989e-01,  6.8780e-01,  4.2793e-01,  4.1824e-01,  6.2082e-01,\n",
      "        -3.2009e-01,  2.2276e-01, -3.9254e-01,  7.3613e-01,  6.0898e-01,\n",
      "         1.3027e+00, -9.5782e-01,  4.3057e-01,  1.0597e+00,  4.6820e-01,\n",
      "         6.4452e-01, -6.6511e-01,  9.9324e-01,  1.0966e-01, -3.7534e-03,\n",
      "        -3.7560e-01,  5.1478e-01,  3.1892e-01, -1.2880e+00, -5.3801e-01,\n",
      "         8.0478e-01, -7.6659e-01, -1.3477e+00, -6.8591e-01, -4.3605e-01,\n",
      "        -1.1177e+00,  4.5437e-02, -2.3554e-01,  2.3523e-01, -1.9146e+00,\n",
      "         8.8046e-01,  4.0601e-01,  4.0761e-01,  5.3337e-01,  1.1351e-01,\n",
      "        -6.2284e-01,  3.6856e-01,  5.3711e-01, -9.3156e-01,  1.1331e+00,\n",
      "        -7.6021e-01, -2.1998e-01,  7.7586e-01, -2.2808e-01, -1.0496e+00,\n",
      "        -3.0241e-02,  4.5645e-01,  1.2050e+00, -3.2072e-01,  6.7267e-01,\n",
      "        -3.5659e-01,  2.0763e-01, -7.7732e-01,  2.3260e+00, -3.8256e-01,\n",
      "         3.4012e-01, -4.5525e-01, -6.8964e-01, -3.1853e+00, -1.0807e+00,\n",
      "         1.0244e+00, -5.1371e-01,  1.0166e-01, -1.7587e-01, -5.3395e-01,\n",
      "        -3.9148e-01,  6.9833e-01,  8.1320e-01, -2.7737e-01,  2.4286e-01,\n",
      "        -1.2293e+00,  3.1886e-01, -4.3495e-01, -1.7463e-01, -7.7523e-01,\n",
      "         1.3157e+00, -3.8682e-02,  7.8580e-01, -7.5470e-01, -2.1569e-01,\n",
      "         5.0051e-01,  1.1665e+00, -3.9920e-01,  1.0931e+00,  6.1296e-01,\n",
      "        -3.1742e-01,  5.1868e-01,  1.5888e+00, -3.6932e-01,  2.1032e-01,\n",
      "        -4.0462e-01, -7.6277e-01, -8.0757e-02,  1.1291e+00, -8.9159e-01,\n",
      "        -1.0162e-01,  4.6043e-01, -1.0535e+00,  3.4386e-01,  1.7051e+00,\n",
      "         2.0428e-02, -7.3159e-01, -9.4589e-01, -4.7128e-01, -5.7715e-01,\n",
      "        -5.8939e-01,  7.1261e-01,  5.9063e-01,  5.4349e-01, -7.4764e-01,\n",
      "        -3.7587e-01, -1.4020e+00,  1.6585e-01, -5.7838e-01,  2.9460e-01,\n",
      "        -1.1895e+00, -1.1902e+00, -8.4399e-01, -2.6829e-01,  1.3249e+00,\n",
      "         8.4566e-01,  7.3692e-02, -2.0736e-01,  1.3382e+00, -5.7119e-02,\n",
      "         4.5904e-01,  3.9393e-01,  9.5043e-02, -2.3772e-01,  8.4419e-01,\n",
      "        -6.9598e-01, -3.2075e-01, -1.5754e+00, -1.2237e+00,  1.9483e+00,\n",
      "         5.1196e-01, -4.2760e-01, -9.5152e-01, -3.4054e-01, -3.0144e-01,\n",
      "        -3.5930e-01, -1.7765e-02, -1.0919e+00,  1.0718e+00,  4.7876e-01,\n",
      "         1.1163e-01,  9.8692e-01,  2.5311e-01, -3.2417e-01, -1.0047e+00,\n",
      "        -4.0324e-01, -1.1929e+00, -7.7493e-01, -1.2209e+00, -1.5308e+00,\n",
      "        -1.2341e-01, -6.6551e-02,  1.2338e+00, -2.8547e-01,  9.1271e-01,\n",
      "         3.8274e-01, -6.9291e-01, -8.9046e-01, -7.2322e-01, -5.7858e-02,\n",
      "        -8.3520e-01,  7.9705e-01, -3.5136e-01, -7.8828e-01, -4.8552e-01,\n",
      "        -2.1587e-01,  1.2527e-01,  6.7919e-01,  2.4630e-01,  4.7664e-01,\n",
      "        -9.4821e-01,  7.2039e-01,  1.0386e+00, -6.5821e-02, -6.8938e-01,\n",
      "        -8.1713e-01,  8.2571e-01,  1.5399e-01, -2.4211e-01,  7.2520e-01,\n",
      "         1.1976e+00,  1.0410e+00, -4.2345e-01,  9.7089e-01,  7.2572e-02,\n",
      "        -4.5008e-01, -2.2165e-01,  5.4243e-01, -7.0724e-01, -4.9255e-01,\n",
      "        -4.0947e-01, -5.0070e-02,  4.3151e-01, -1.8594e-01, -7.1354e-01,\n",
      "        -7.9702e-01, -4.6429e-01,  1.7216e-01,  3.7968e-01,  8.7259e-01,\n",
      "        -2.4313e-01, -4.4124e-01, -4.9356e-01, -5.8094e-02,  8.8618e-01,\n",
      "         1.3696e-01,  1.1772e+00, -6.0429e-01, -4.1628e-02,  1.3383e-01,\n",
      "        -6.1860e-02, -1.2947e+00,  3.5626e-01,  1.0407e+00, -2.5689e-01,\n",
      "         4.6325e-02, -3.0389e-01, -2.7737e-01, -1.0103e+00,  8.2367e-01,\n",
      "        -3.8544e-01,  1.0079e+00,  3.6267e-01,  5.0382e-01, -5.0722e-01,\n",
      "        -1.2529e+00, -1.3420e+00,  7.3451e-02,  3.2728e-01, -1.0705e+00,\n",
      "        -6.4286e-01,  1.1899e-01,  1.3995e-01, -9.9011e-02, -1.7338e+00,\n",
      "        -4.5933e-01, -1.0126e+00, -8.0805e-01,  4.5939e-01, -5.0012e-01,\n",
      "        -6.6118e-01,  3.2293e-01, -3.5375e-02,  3.0225e-01,  5.3267e-01,\n",
      "        -2.4908e-01, -9.3058e-01, -7.2292e-01, -7.5489e-01,  1.2412e-01,\n",
      "         5.3176e-03,  6.9390e-01,  3.6835e-02, -1.9254e-01, -2.0743e-01,\n",
      "        -7.1198e-01,  9.4736e-01, -4.4292e-02,  1.1846e+00,  1.2850e-01,\n",
      "         1.2678e+00, -3.3810e-01, -7.1318e-01,  1.6056e-01, -8.8739e-01,\n",
      "         2.3944e-02,  2.4212e-01,  4.4648e-01, -7.3177e-01, -1.0855e-01,\n",
      "        -1.0740e+00,  1.1417e+00, -2.0587e-01,  3.1363e-01,  5.9536e-01,\n",
      "         9.6437e-02,  2.2383e+00, -1.3830e-01, -5.5728e-01, -2.8935e-01,\n",
      "        -8.5416e-01, -7.9856e-01,  1.4109e+00,  6.4099e-01,  6.7431e-01,\n",
      "         1.4748e+00,  1.5907e-01, -6.3736e-01, -2.0457e-01,  1.5119e-01,\n",
      "        -7.9070e-01, -2.9011e-01,  6.7689e-01,  6.9902e-01, -1.0649e+00,\n",
      "         1.0984e-01,  1.0660e+00, -4.3684e-01,  1.6024e+00, -2.7580e-01,\n",
      "         1.1006e-01, -8.1982e-01,  1.0592e+00, -1.0610e-01,  1.1585e-01,\n",
      "         4.7200e-01, -4.9539e-01, -6.7324e-01, -1.3227e-01, -2.3580e-01,\n",
      "         1.4974e+00, -3.4765e-01,  4.2267e-01,  2.1085e-01, -3.9593e-01,\n",
      "        -8.8857e-01,  1.6424e+00, -1.0448e+00,  1.7911e+00, -1.9921e-01,\n",
      "         1.4113e+00, -8.0246e-01,  9.3999e-01, -3.5191e-01,  7.5833e-01,\n",
      "        -7.9113e-01,  1.5846e+00,  1.5286e-01, -6.5610e-01, -2.4943e-01,\n",
      "         1.1186e-01,  7.2970e-01,  1.2969e+00,  3.4895e-01, -9.2690e-02,\n",
      "        -9.4118e-01, -7.1189e-01, -3.4629e-01, -1.8212e-01, -7.8485e-01,\n",
      "        -5.6044e-01,  3.0533e-01, -1.5063e-01, -1.0490e+00, -1.1335e+00,\n",
      "         9.9588e-01,  3.2603e-01,  3.5315e-01,  3.8136e-02, -9.9689e-01,\n",
      "         7.2417e-02, -2.4232e+00, -5.1102e-02,  9.4091e-01,  1.4341e+00,\n",
      "        -1.9282e-01, -1.4144e+00, -6.1360e-01, -2.9523e-01,  2.1977e-01,\n",
      "        -3.7542e-02,  1.1395e+00,  7.2485e-01, -4.5628e-01, -1.0709e+00,\n",
      "        -1.3806e+00, -1.1405e-01,  9.7557e-01, -3.1075e-01, -1.3883e+00,\n",
      "         8.9060e-01,  9.5943e-01,  6.5694e-01, -5.8602e-01, -7.8438e-01,\n",
      "         1.5133e-01, -2.0878e+00,  4.4171e-01,  9.1854e-01,  1.9532e-01,\n",
      "        -4.1091e-01,  4.2526e-01,  6.5919e-02, -7.0215e-01,  4.5818e-01,\n",
      "        -5.1330e-01,  8.9859e-01, -5.8071e-01,  5.8034e-01,  7.8960e-01,\n",
      "         4.1283e-01,  7.8706e-01,  1.2158e+00, -3.1244e-01,  8.2688e-01,\n",
      "         7.6145e-02, -9.7843e-01,  1.1306e+00,  6.7465e-01,  7.5644e-01,\n",
      "        -6.7143e-01, -9.6860e-01, -6.0042e-01,  1.2669e+00, -4.6659e-01,\n",
      "         1.9371e+00,  1.2931e+00,  3.2988e-01,  4.3456e-01,  1.1174e+00,\n",
      "        -9.6568e-02,  2.1862e-01, -1.1688e+00,  1.5536e-01,  1.3112e-01,\n",
      "        -9.2917e-01, -1.0009e+00, -8.2766e-01, -4.1680e-01,  9.1027e-01,\n",
      "        -1.5952e-01,  6.8745e-01,  2.3455e+00,  1.4036e-01,  9.8665e-01,\n",
      "        -8.8334e-02,  4.6612e-01, -4.9635e-02, -3.7541e-01, -4.4032e-01,\n",
      "        -2.9778e-01, -1.5253e+00,  2.5098e-01, -2.5315e-01, -6.8863e-01,\n",
      "        -8.6542e-01,  3.0293e-01,  2.5221e-01])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# 加载预训练模型和tokenizer\n",
    "model_name = './pretrained_bert'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# 准备输入数据\n",
    "text = \"This is an example sentence.\"\n",
    "encoded = tokenizer.encode_plus(text, add_special_tokens=True, \n",
    "                                padding='max_length', truncation=True, \n",
    "                                max_length=128, return_tensors='pt')\n",
    "input_ids = encoded['input_ids']\n",
    "attention_mask = encoded['attention_mask']\n",
    "\n",
    "# 获取词嵌入\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    embeddings = outputs[0]\n",
    "\n",
    "print(f'Input text: {text}')\n",
    "print(f'Word embeddings shape: {embeddings.shape}')\n",
    "print(f'First word embedding: {embeddings[0][1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21128, 768, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = bert_config\n",
    "config.vocab_size, config.hidden_size, config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertModel = BertModel(bert_config)\n",
    "BertModel.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertModel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
